{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2865738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c286e919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jahhk5gZWG3GS7AH0FA_emtKvSZbfCWK\n"
     ]
    }
   ],
   "source": [
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API_KEY not found. Make sure it's set in your .env file.\")\n",
    "else:\n",
    "    print(API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0cd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker, start_date, end_date, api_key):\n",
    "    URL = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/hour/{start_date}/{end_date}\"\n",
    "    params = {\n",
    "        \"apiKey\": api_key,  # ✅ Correct parameter name\n",
    "        \"adjusted\": \"true\",\n",
    "        \"sort\": \"asc\",       # ✅ Keeps results in ascending (oldest → newest) order\n",
    "        \"limit\": 50000\n",
    "    }\n",
    "\n",
    "    print(f\"Fetching data for {ticker} from {start_date} to {end_date}...\")\n",
    "    response = requests.get(URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'results' in data and data['results']:\n",
    "            df = pd.DataFrame(data['results'])\n",
    "            df = df.rename(columns={'o': 'open', 'h': 'high', 'l': 'low', 'c': 'close', 't': 'timestamp', 'v': 'volume'})\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "            df['ticker'] = ticker\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"No results found for {ticker}.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Error fetching data for {ticker}: {response.status_code} - {response.text}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5f91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for XOM from 2020-01-01 to 2025-10-13...\n",
      "Fetching data for CVX from 2020-01-01 to 2025-10-13...\n",
      "Fetching data for WTI from 2020-01-01 to 2025-10-13...\n",
      "Fetching data for COP from 2020-01-01 to 2025-10-13...\n",
      "Fetching data for BP from 2020-01-01 to 2025-10-13...\n",
      "\n",
      "⏳ Processed 5 tickers, waiting 60 seconds to avoid rate limits...\n",
      "\n",
      "Fetching data for EOG from 2020-01-01 to 2025-10-13...\n",
      "Fetching data for PBR from 2020-01-01 to 2025-10-13...\n",
      "\n",
      "Successfully fetched and saved data for 7 tickers.\n",
      "Raw data saved to: ../data/raw/oil_stocks_hourly_raw.csv\n",
      "     volume        vw    open   close    high     low           timestamp  \\\n",
      "0    6556.0  107.3982  107.16  107.41  107.55  107.16 2023-10-13 08:00:00   \n",
      "1   15550.0  107.7053  107.49  107.68  108.00  107.40 2023-10-13 09:00:00   \n",
      "2   36300.0  108.0503  107.84  107.80  108.29  107.79 2023-10-13 10:00:00   \n",
      "3   68418.0  107.6703  107.78  107.82  107.85  107.50 2023-10-13 11:00:00   \n",
      "4  213367.0  107.8121  107.81  107.95  108.14  106.47 2023-10-13 12:00:00   \n",
      "\n",
      "      n ticker  \n",
      "0    60    XOM  \n",
      "1   221    XOM  \n",
      "2   380    XOM  \n",
      "3   803    XOM  \n",
      "4  1632    XOM  \n"
     ]
    }
   ],
   "source": [
    "tickers_to_fetch = ['XOM', 'CVX', 'WTI', 'COP', 'BP', 'EOG', 'PBR']\n",
    "start_date_str = \"2020-01-01\"\n",
    "end_date_str = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# 2. Loop through tickers\n",
    "all_data = []\n",
    "for i, ticker in enumerate(tickers_to_fetch, start=1):\n",
    "    stock_df = fetch_stock_data(ticker, start_date_str, end_date_str, API_KEY)\n",
    "    if not stock_df.empty:\n",
    "        all_data.append(stock_df)\n",
    "    if i%5 == 0 and i < len(tickers_to_fetch):\n",
    "        print(f\"\\n⏳ Processed {i} tickers, waiting 60 seconds to avoid rate limits...\\n\")\n",
    "        time.sleep(60)\n",
    "\n",
    "# 3. Combine and save\n",
    "if all_data:\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    output_path = \"../data/raw/oil_stocks_hourly_raw.csv\"\n",
    "    final_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSuccessfully fetched and saved data for {len(all_data)} tickers.\")\n",
    "    print(f\"Raw data saved to: {output_path}\")\n",
    "    print(final_df.head())\n",
    "else:\n",
    "    print(\"No data was fetched. Please check your tickers, date range, and API key.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d1e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"../data/raw/oil_stocks_hourly_raw.csv\"\n",
    "df = pd.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f1f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded raw data with the following details:\n",
      "Shape: (10514, 9)\n",
      "Columns: ['volume', 'vw', 'open', 'close', 'high', 'low', 'timestamp', 'n', 'ticker']\n",
      "     volume        vw    open   close    high     low            timestamp  \\\n",
      "0    6556.0  107.3982  107.16  107.41  107.55  107.16  2023-10-13 08:00:00   \n",
      "1   15550.0  107.7053  107.49  107.68  108.00  107.40  2023-10-13 09:00:00   \n",
      "2   36300.0  108.0503  107.84  107.80  108.29  107.79  2023-10-13 10:00:00   \n",
      "3   68418.0  107.6703  107.78  107.82  107.85  107.50  2023-10-13 11:00:00   \n",
      "4  213367.0  107.8121  107.81  107.95  108.14  106.47  2023-10-13 12:00:00   \n",
      "\n",
      "      n ticker  \n",
      "0    60    XOM  \n",
      "1   221    XOM  \n",
      "2   380    XOM  \n",
      "3   803    XOM  \n",
      "4  1632    XOM  \n"
     ]
    }
   ],
   "source": [
    "print(\"Successfully loaded raw data with the following details:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2c8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Calculate the Log Percent Change ---\n",
    "# This is the primary feature the model will use.\n",
    "# It's calculated using the 'open' and 'close' columns you provided.\n",
    "# We add a tiny number (epsilon) to the denominator to prevent division by zero errors.\n",
    "epsilon = 1e-8\n",
    "df['log_percent_change'] = np.log(df['close'] / (df['open'] + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ff392ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data has been pivoted. The new format is:\n",
      "Shape: (2002, 7)\n",
      "ticker                     BP           COP       CVX           EOG       PBR  \\\n",
      "timestamp                                                                       \n",
      "2023-10-13 08:00:00  0.004252 -8.164591e-11  0.000737 -7.642342e-11  0.008606   \n",
      "2023-10-13 09:00:00 -0.002498 -8.141332e-11  0.002206 -7.642342e-11  0.004613   \n",
      "2023-10-13 10:00:00  0.002746 -8.141332e-11 -0.001282 -7.642342e-11  0.001970   \n",
      "2023-10-13 11:00:00 -0.001248  2.354757e-03  0.001346  7.621653e-05  0.009859   \n",
      "2023-10-13 12:00:00  0.000962  8.178514e-03  0.003599 -4.561011e-03  0.007187   \n",
      "\n",
      "ticker                        WTI       XOM  \n",
      "timestamp                                    \n",
      "2023-10-13 08:00:00  2.472187e-03  0.002330  \n",
      "2023-10-13 09:00:00  2.472187e-03  0.001766  \n",
      "2023-10-13 10:00:00 -2.481390e-09 -0.000371  \n",
      "2023-10-13 11:00:00  7.380105e-03  0.000371  \n",
      "2023-10-13 12:00:00  2.472187e-03  0.001298  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_19300\\2683735512.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  processed_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_19300\\2683735512.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  processed_df.fillna(method='bfill', inplace=True) # Fill any remaining NaNs at the start\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Restructure (Pivot) the DataFrame ---\n",
    "# The model needs the data in a \"wide\" format where each ticker is a feature column.\n",
    "# We'll set 'timestamp' as the row index and create a new column for each unique 'ticker'.\n",
    "processed_df = df.pivot_table(index='timestamp', columns='ticker', values='log_percent_change')\n",
    "\n",
    "# After pivoting, missing values can appear. We'll fill them using the last valid observation.\n",
    "processed_df.fillna(method='ffill', inplace=True)\n",
    "processed_df.fillna(method='bfill', inplace=True) # Fill any remaining NaNs at the start\n",
    "\n",
    "print(\"\\nData has been pivoted. The new format is:\")\n",
    "print(f\"Shape: {processed_df.shape}\")\n",
    "print(processed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b5e1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete. Model-ready data saved to: ../data/processed/oil_stocks_hourly_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Save the Final Processed File ---\n",
    "# This clean file will be used by your PyTorch Dataset for model training.\n",
    "processed_data_path = \"../data/processed/oil_stocks_hourly_processed.csv\"\n",
    "processed_df.to_csv(processed_data_path)\n",
    "\n",
    "print(f\"\\nPreprocessing complete. Model-ready data saved to: {processed_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
